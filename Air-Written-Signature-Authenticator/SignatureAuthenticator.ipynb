{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_AUTH_DIR = r'dataset\\train\\authentic'\n",
    "TRAIN_FORG_DIR = r'dataset\\train\\forged'\n",
    "\n",
    "TEST_DIR = r'dataset\\test'\n",
    "IMG_ROW, IMG_COL = 159, 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in os.listdir(TRAIN_AUTH_DIR):\n",
    "        if img[0] != '.' : \n",
    "            path = os.path.join(TRAIN_AUTH_DIR, img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            training_data.append([np.array(img_data), 1])\n",
    "    for img in os.listdir(TRAIN_FORG_DIR):\n",
    "        if img[0] != '.' : \n",
    "            path = os.path.join(TRAIN_FORG_DIR, img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            training_data.append([np.array(img_data), 0])\n",
    "    \n",
    "    shuffle(training_data)\n",
    "    np.save(r'metadata\\train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "imgname = []\n",
    "def create_test_data():\n",
    "    testing_data = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        if img[0] != '.' :\n",
    "            path = os.path.join(TEST_DIR, img)\n",
    "            imgname.append(img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            testing_data.append(np.array(img_data))\n",
    "\n",
    "    np.save(r'metadata\\test_data.npy', testing_data)\n",
    "    return testing_data\n",
    "\n",
    "\n",
    "train_file = r'metadata\\train_data.npy'\n",
    "test_file = r'metadata\\test_data.npy'\n",
    "\n",
    "if os.path.exists(train_file) and os.path.exists(test_file):\n",
    "    train_data = np.load(train_file, allow_pickle=True)\n",
    "    test_data = np.load(test_file, allow_pickle=True)\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        if img[0] != '.' :\n",
    "            imgname.append(img)\n",
    "    print('Found numpy data on drive. Loaded.')\n",
    "    \n",
    "else:\n",
    "    print('Creating numpy data.')\n",
    "    train_data = create_train_data()\n",
    "    test_data = create_test_data()\n",
    "    print('Numpy data created.')\n",
    "    \n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([x[0] for x in train_data]).reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "y_train = np.array([x[1] for x in train_data])\n",
    "\n",
    "X_test = np.array([x for x in test_data]).reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "\n",
    "if os.path.exists(r'metadata\\model.h5'):\n",
    "    model = load_model(r'metadata\\model.h5')\n",
    "    print('Found saved model on drive. Loaded.')\n",
    "\n",
    "else:\n",
    "    print('Building model.')    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, input_shape=(IMG_ROW, IMG_COL, 1), kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPool2D((2)))\n",
    "    model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    print('Compiling model.')\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.002), metrics=['accuracy'])\n",
    "    \n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "\n",
    "print('Fitting Model. Please Wait.')\n",
    "model.fit(X_train, y_train, batch_size=5, epochs=10, verbose=1, validation_split=0.10)\n",
    "\n",
    "print('Model Fitting Finished.')\n",
    "\n",
    "model.save(r'metadata\\model.h5')\n",
    "print('Model Saved.')\n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test)\n",
    "\n",
    "print('Authenticity predicted : ')\n",
    "for i in range(len(output)):\n",
    "    print(imgname[i], \": %.3f %%\" % (output[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
