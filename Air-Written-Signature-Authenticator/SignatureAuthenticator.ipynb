{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_AUTH_DIR = r'dataset\\train\\authentic'\n",
    "TRAIN_FORG_DIR = r'dataset\\train\\forged'\n",
    "\n",
    "TEST_DIR = r'dataset\\test'\n",
    "IMG_ROW, IMG_COL = 159, 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating numpy data.\n",
      "Numpy data created.\n",
      "You may proceed!\n"
     ]
    }
   ],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in os.listdir(TRAIN_AUTH_DIR):\n",
    "        if img[0] != '.' : \n",
    "            path = os.path.join(TRAIN_AUTH_DIR, img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            training_data.append([np.array(img_data), 1])\n",
    "    for img in os.listdir(TRAIN_FORG_DIR):\n",
    "        if img[0] != '.' : \n",
    "            path = os.path.join(TRAIN_FORG_DIR, img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            training_data.append([np.array(img_data), 0])\n",
    "    \n",
    "    shuffle(training_data)\n",
    "    np.save(r'metadata\\train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "imgname = []\n",
    "def create_test_data():\n",
    "    testing_data = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        if img[0] != '.' :\n",
    "            path = os.path.join(TEST_DIR, img)\n",
    "            imgname.append(img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.divide(img_data, 255)\n",
    "            img_data = cv2.resize(img_data, (IMG_ROW, IMG_COL))\n",
    "            testing_data.append(np.array(img_data))\n",
    "\n",
    "    np.save(r'metadata\\test_data.npy', testing_data)\n",
    "    return testing_data\n",
    "\n",
    "\n",
    "train_file = r'metadata\\train_data.npy'\n",
    "test_file = r'metadata\\test_data.npy'\n",
    "\n",
    "if os.path.exists(train_file) and os.path.exists(test_file):\n",
    "    train_data = np.load(train_file, allow_pickle=True)\n",
    "    test_data = np.load(test_file, allow_pickle=True)\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        if img[0] != '.' :\n",
    "            imgname.append(img)\n",
    "    print('Found numpy data on drive. Loaded.')\n",
    "    \n",
    "else:\n",
    "    print('Creating numpy data.')\n",
    "    train_data = create_train_data()\n",
    "    test_data = create_test_data()\n",
    "    print('Numpy data created.')\n",
    "    \n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "WARNING:tensorflow:From C:\\Users\\Oishik\\Anaconda3\\envs\\ml_env_1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Oishik\\Anaconda3\\envs\\ml_env_1\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Compiling model.\n",
      "You may proceed!\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([x[0] for x in train_data]).reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "y_train = np.array([x[1] for x in train_data])\n",
    "\n",
    "X_test = np.array([x for x in test_data]).reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "\n",
    "if os.path.exists(r'metadata\\model.h5'):\n",
    "    model = load_model(r'metadata\\model.h5')\n",
    "    print('Found saved model on drive. Loaded.')\n",
    "\n",
    "else:\n",
    "    print('Building model.')    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, input_shape=(IMG_ROW, IMG_COL, 1), kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPool2D((2)))\n",
    "    model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    print('Compiling model.')\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.002), metrics=['accuracy'])\n",
    "    \n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model. Please Wait.\n",
      "Train on 223 samples, validate on 25 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Oishik\\Anaconda3\\envs\\ml_env_1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 14s 65ms/sample - loss: 0.3487 - acc: 0.8117 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 12s 53ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1019e-04 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 12s 54ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 4.9890e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 12s 55ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 4.4228e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 12s 53ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 4.0783e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 12s 52ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 3.8055e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 12s 53ms/sample - loss: 9.4206e-04 - acc: 1.0000 - val_loss: 3.6194e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 12s 53ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 3.4264e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 12s 54ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 3.2430e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 12s 55ms/sample - loss: 9.0425e-04 - acc: 1.0000 - val_loss: 3.0900e-04 - val_acc: 1.0000\n",
      "Model Fitting Finished.\n",
      "Model Saved.\n",
      "You may proceed!\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "print('Fitting Model. Please Wait.')\n",
    "model.fit(X_train, y_train, batch_size=5, epochs=10, verbose=1, validation_split=0.10)\n",
    "\n",
    "print('Model Fitting Finished.')\n",
    "\n",
    "model.save(r'metadata\\model.h5')\n",
    "print('Model Saved.')\n",
    "print('You may proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticity predicted : \n",
      "img 2019-12-02 11-34-16.png : 99.962 %\n",
      "img 2019-12-02 11-34-50.png : 6.388 %\n",
      "img 2019-12-02 11-35-14.png : 14.752 %\n",
      "img 2019-12-02 11-35-30.png : 3.615 %\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(X_test)\n",
    "\n",
    "print('Authenticity predicted : ')\n",
    "for i in range(len(output)):\n",
    "    print(imgname[i], \": %.3f %%\" % (output[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}